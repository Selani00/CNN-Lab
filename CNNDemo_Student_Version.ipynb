{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selani00/CNN-Lab/blob/main/CNNDemo_Student_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Implementation with PyTorch"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b0d27821aa5691a1"
      },
      "id": "b0d27821aa5691a1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: CIFAR10 (Ref: https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "Info: <br>\n",
        "> Number of Images: 60000,  32 * 32 in resolution\n",
        "> Number of Classes: 10 (Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck)\n",
        "\n",
        "**Prerequisites**\n",
        "> PyTorch Basics: https://youtu.be/OIenNRt2bjg\n",
        "> Python Basics: https://youtu.be/rfscVS0vtbw\n",
        "\n",
        "**References:**\n",
        "1. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "2. https://wandb.ai/authors/ayusht/reports/Implementing-Dropout-Regularization-in-PyTorch--VmlldzoxNTgwOTE\n",
        "3. https://medium.com/artificialis/dropout-regularization-using-pytorch-in-python-7765337cb158\n",
        "3. https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
        "4. https://pytorch.org/vision/main/datasets.html\n",
        "5. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "6. https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html#:~:text=Tensors%20are%20a%20specialized%20data,GPUs%20or%20other%20hardware%20accelerators."
      ],
      "metadata": {
        "collapsed": false,
        "id": "c01cc97e25cc1bcd"
      },
      "id": "c01cc97e25cc1bcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Google Drive"
      ],
      "metadata": {
        "id": "zyJi040mgg6Q"
      },
      "id": "zyJi040mgg6Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Google drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PXwYQtTIgkB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad775f17-97d0-41b6-c38d-33e589f1f06f"
      },
      "id": "PXwYQtTIgkB9",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Necessary Libraries"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9679f61635195c82"
      },
      "id": "9679f61635195c82"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:12.154311Z",
          "start_time": "2024-03-30T14:08:28.698564Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define transforms (Data Augmentation)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ba3bed2cfd7fcaa5"
      },
      "id": "ba3bed2cfd7fcaa5"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torchvision.transforms' has no attribute 'ToTenser'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b63631333805>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m transform_train=transforms.Compose([\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTenser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormaliza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ])\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'ToTenser'"
          ]
        }
      ],
      "source": [
        "# Define transforms\n",
        "\n",
        "# For training set\n",
        "transform_train=transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTenser(),\n",
        "    transforms.Normaliza(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "# For testing set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTenser(),\n",
        "    transforms.Normaliza(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:12.247913Z",
          "start_time": "2024-03-30T14:09:12.158327Z"
        },
        "id": "ba4df284b458abd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "f0a11882-309a-4adb-bcfa-2dbb6a83926c"
      },
      "id": "ba4df284b458abd7",
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors**\n",
        "> - Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "> - Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data.\n",
        "> - Tensors are also optimized for automatic differentiation.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9a68463871691fb"
      },
      "id": "9a68463871691fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets and define the\n",
        "\n",
        "Torchvision provides many built-in datasets in the torchvision.datasets module, as well as utility classes for building your own datasets (https://pytorch.org/vision/main/datasets.html).\n",
        "\n",
        "> PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ff3fb0dda423abf6"
      },
      "id": "ff3fb0dda423abf6"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='/data',train=True,download=True, transform=transform_train)\n",
        "testset= torchvision.datasets.CIFAR10(root='/data',train=False,download=True, transform=transform_train)\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:16.868601Z",
          "start_time": "2024-03-30T14:09:12.249926Z"
        },
        "id": "1da9eeafe686a485"
      },
      "id": "1da9eeafe686a485",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define batch size\n",
        "batch_size=25\n",
        "\n",
        "# created dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size, shuffle= True)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=batch_size, shuffle= False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:16.878884Z",
          "start_time": "2024-03-30T14:09:16.871611Z"
        },
        "id": "3dd43fd1d88a18ac"
      },
      "id": "3dd43fd1d88a18ac",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Here we have used only two sets are training and the testing tests. However, for the hyperparameter tuning we need the validation set as well. Therefore, find out a solution to split the test set into two and, redo the dataset loading and dataloader preparation."
      ],
      "metadata": {
        "collapsed": false,
        "id": "a87aa6330f93dd72"
      },
      "id": "a87aa6330f93dd72"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define the classes in the dataset\n",
        "classes = ['airplane','automobile','bird','cat','dog','deer','frog','ship','track']\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:16.888166Z",
          "start_time": "2024-03-30T14:09:16.880896Z"
        },
        "id": "760884391aa0bb"
      },
      "id": "760884391aa0bb",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display a Sample of Images"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3a8b7b6e22c41764"
      },
      "id": "3a8b7b6e22c41764"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Visualize a batch of images\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5;  # Unnormalized\n",
        "    # Convert image into a Numpy Array for data manipuation and usage in\n",
        "    # matplotlib\n",
        "    npimg = img.numpy()\n",
        "    # In numpy images defined as no. of channels, height, width format\n",
        "    # However, matplotlib expects in height, width, channels format\n",
        "    # So, we need to transform the npimg.\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images,labels= next(dataiter)\n",
        "\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.makegrid(images,nrows=5))\n",
        "\n",
        "# Print labels\n",
        "print(''.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:19.683824Z",
          "start_time": "2024-03-30T14:09:16.890179Z"
        },
        "id": "a4a5cfdaaa43edb0"
      },
      "id": "a4a5cfdaaa43edb0",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN"
      ],
      "metadata": {
        "collapsed": false,
        "id": "bd8ff3e6becd7bc0"
      },
      "id": "bd8ff3e6becd7bc0"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,6,5,1,0)\n",
        "    self.bn1=nn.BatchNorm2s(6)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn. Conv2d(6,16,3)\n",
        "    self.bn2=nn.BatchNorm2d(16)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 =nn.Linear(16*6*6,144)\n",
        "    self.bn3=nn.BatchNorm1d(144)\n",
        "    self.fc2=nn.Linear(144,72)\n",
        "    self.fc3=nn.Linear(72,10)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:19.696223Z",
          "start_time": "2024-03-30T14:09:19.686842Z"
        },
        "id": "c127e729292a188"
      },
      "id": "c127e729292a188",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Initialize a instance of the model\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:19.843020Z",
          "start_time": "2024-03-30T14:09:19.698240Z"
        },
        "id": "9ddb232f4f517536"
      },
      "id": "9ddb232f4f517536",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Device"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cc40eefd0eaa05f0"
      },
      "id": "cc40eefd0eaa05f0"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# If cuda GPU is available, it will be set as the device otherwise cpu\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:23.548188Z",
          "start_time": "2024-03-30T14:09:23.539537Z"
        },
        "id": "b3ac3e140eca8856"
      },
      "id": "b3ac3e140eca8856",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Transfer model to the device\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:23.561159Z",
          "start_time": "2024-03-30T14:09:23.552207Z"
        },
        "id": "1b543360bc4554b"
      },
      "id": "1b543360bc4554b",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Generate model summary\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:23.533524Z",
          "start_time": "2024-03-30T14:09:19.846033Z"
        },
        "id": "1a957f13e936a949"
      },
      "id": "1a957f13e936a949",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Loss Function and Optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d1a33fb3f6ff6908"
      },
      "id": "d1a33fb3f6ff6908"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define loss function and the optimizer\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:09:23.571174Z",
          "start_time": "2024-03-30T14:09:23.564173Z"
        },
        "id": "669b1307469f8832"
      },
      "id": "669b1307469f8832",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6f968a2a28030777"
      },
      "id": "6f968a2a28030777"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Train the defined model\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:26:17.494438Z",
          "start_time": "2024-03-30T14:09:23.573186Z"
        },
        "id": "60e69b0014c4237f"
      },
      "id": "60e69b0014c4237f",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Saving and Loading"
      ],
      "metadata": {
        "collapsed": false,
        "id": "f13832606b350125"
      },
      "id": "f13832606b350125"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Saving\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:26:21.342211Z",
          "start_time": "2024-03-30T14:26:21.117945Z"
        },
        "id": "ea62c240afc3da9d"
      },
      "id": "ea62c240afc3da9d",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Loading\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:26:59.892876Z",
          "start_time": "2024-03-30T14:26:59.659958Z"
        },
        "id": "fe0a4d8e1129b93a"
      },
      "id": "fe0a4d8e1129b93a",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Once more send the model to the device after loading\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:27:53.129933Z",
          "start_time": "2024-03-30T14:27:53.112174Z"
        },
        "id": "9cd3b98741e08c5a"
      },
      "id": "9cd3b98741e08c5a",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance with Testset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e79c54f0039db3bf"
      },
      "id": "e79c54f0039db3bf"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Measure performance of the test set\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:28:02.211350Z",
          "start_time": "2024-03-30T14:27:55.961008Z"
        },
        "id": "fbe1e1188dbad085"
      },
      "id": "fbe1e1188dbad085",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "In the above cases, we did not utilized any validation set and no hyperparameter tuning has been performed either. So model performance should be able to improve by performing some hyperparameter tuning."
      ],
      "metadata": {
        "collapsed": false,
        "id": "b4dd7a68927c5aed"
      },
      "id": "b4dd7a68927c5aed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Furthermore, try to measure the training and validation set losses/accuracies within the training loop and plot them in a single plot. In this way, we will be able to identify whether model is overfitting or not. In the above case, neither training or validation losses/accuracies were calculated. Try to record the performance once per certain number of batches."
      ],
      "metadata": {
        "collapsed": false,
        "id": "83740c3f826b0765"
      },
      "id": "83740c3f826b0765"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Try to integrate early stopping into the training loop when the model performance w.r.t the validation set is no longer improving with further training. Try to think of a possible logic and add that into the training loop accordingly."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7ac71a674a54e912"
      },
      "id": "7ac71a674a54e912"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance for Different Classes"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3e266ad502f16426"
      },
      "id": "3e266ad502f16426"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Measure the performance w.r.t each class\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T14:28:14.016435Z",
          "start_time": "2024-03-30T14:28:02.717706Z"
        },
        "id": "dfc3e8f7211ab7e1"
      },
      "id": "dfc3e8f7211ab7e1",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}