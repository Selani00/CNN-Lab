{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Implementation with PyTorch"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b0d27821aa5691a1"
      },
      "id": "b0d27821aa5691a1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: CIFAR10 (Ref: https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "Info: <br>\n",
        "> Number of Images: 60000,  32 * 32 in resolution\n",
        "> Number of Classes: 10 (Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck)\n",
        "\n",
        "**Prerequisites**\n",
        "> PyTorch Basics: https://youtu.be/OIenNRt2bjg\n",
        "> Python Basics: https://youtu.be/rfscVS0vtbw\n",
        "\n",
        "**References:**\n",
        "1. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "2. https://wandb.ai/authors/ayusht/reports/Implementing-Dropout-Regularization-in-PyTorch--VmlldzoxNTgwOTE\n",
        "3. https://medium.com/artificialis/dropout-regularization-using-pytorch-in-python-7765337cb158\n",
        "3. https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
        "4. https://pytorch.org/vision/main/datasets.html\n",
        "5. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "6. https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html#:~:text=Tensors%20are%20a%20specialized%20data,GPUs%20or%20other%20hardware%20accelerators."
      ],
      "metadata": {
        "collapsed": false,
        "id": "c01cc97e25cc1bcd"
      },
      "id": "c01cc97e25cc1bcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Google Drive"
      ],
      "metadata": {
        "id": "Pb6keXViWU8u"
      },
      "id": "Pb6keXViWU8u"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Google drive into Colab"
      ],
      "metadata": {
        "id": "aapyS3bNWZWW"
      },
      "id": "aapyS3bNWZWW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Necessary Libraries"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9679f61635195c82"
      },
      "id": "9679f61635195c82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:01.906238Z",
          "start_time": "2024-03-30T16:28:53.875186Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define transforms (Data Augmentation)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ba3bed2cfd7fcaa5"
      },
      "id": "ba3bed2cfd7fcaa5"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "\n",
        "# For training set\n",
        "\n",
        "# For testing set\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:01.917009Z",
          "start_time": "2024-03-30T16:29:01.909252Z"
        },
        "id": "ba4df284b458abd7"
      },
      "id": "ba4df284b458abd7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors**\n",
        "> - Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "> - Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data.\n",
        "> - Tensors are also optimized for automatic differentiation.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9a68463871691fb"
      },
      "id": "9a68463871691fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets and define the\n",
        "\n",
        "Torchvision provides many built-in datasets in the torchvision.datasets module, as well as utility classes for building your own datasets (https://pytorch.org/vision/main/datasets.html).\n",
        "\n",
        "> PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ff3fb0dda423abf6"
      },
      "id": "ff3fb0dda423abf6"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:03.801574Z",
          "start_time": "2024-03-30T16:29:01.920545Z"
        },
        "id": "1da9eeafe686a485"
      },
      "id": "1da9eeafe686a485",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define batch size\n",
        "\n",
        "# Created dataloaders\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:03.812809Z",
          "start_time": "2024-03-30T16:29:03.804587Z"
        },
        "id": "3dd43fd1d88a18ac"
      },
      "id": "3dd43fd1d88a18ac",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Here we have used only two sets are training and the testing tests. However, for the hyperparameter tuning we need the validation set as well. Therefore, find out a solution to split the test set into two and, redo the dataset loading and dataloader preparation."
      ],
      "metadata": {
        "collapsed": false,
        "id": "a87aa6330f93dd72"
      },
      "id": "a87aa6330f93dd72"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define the classes in the dataset\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:03.825262Z",
          "start_time": "2024-03-30T16:29:03.817827Z"
        },
        "id": "760884391aa0bb"
      },
      "id": "760884391aa0bb",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display a Sample of Images"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3a8b7b6e22c41764"
      },
      "id": "3a8b7b6e22c41764"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Visualize a batch of images\n",
        "\n",
        "def imshow(img):\n",
        "\n",
        "    # Define transform to inverse normalize a image\n",
        "    inv_normalize = transforms.Normalize(\n",
        "        mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
        "        std=[1 / 0.229, 1 / 0.224, 1 / 0.225]\n",
        "    )\n",
        "\n",
        "    # Inverse normalize the image\n",
        "    img = inv_normalize(img)\n",
        "\n",
        "    # Convert image into a Numpy Array for data manipuation and usage in\n",
        "    # matplotlib\n",
        "    npimg = img.numpy()\n",
        "    # In numpy images defined as no. of channels, height, width format\n",
        "    # However, matplotlib expects in height, width, channels format\n",
        "    # So, we need to transform the npimg.\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get some random training images\n",
        "\n",
        "\n",
        "# Show images\n",
        "\n",
        "\n",
        "# Print labels\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:04.458966Z",
          "start_time": "2024-03-30T16:29:03.828280Z"
        },
        "id": "a4a5cfdaaa43edb0"
      },
      "id": "a4a5cfdaaa43edb0",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN"
      ],
      "metadata": {
        "collapsed": false,
        "id": "bd8ff3e6becd7bc0"
      },
      "id": "bd8ff3e6becd7bc0"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Load pretrained model of ResNet18\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:40.805291Z",
          "start_time": "2024-03-30T16:29:04.461102Z"
        },
        "id": "c127e729292a188"
      },
      "id": "c127e729292a188",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Freeze the parameters\n",
        "# So, during the training the the values of these parameters will not be updated\n",
        "\n"
      ],
      "metadata": {
        "id": "54014dc903e5a9f6"
      },
      "id": "54014dc903e5a9f6",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Create the CNN model\n"
      ],
      "metadata": {
        "id": "9e2cf0d9857ab98e"
      },
      "id": "9e2cf0d9857ab98e",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Initialize a instance of the model\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:40.834739Z",
          "start_time": "2024-03-30T16:29:40.825992Z"
        },
        "id": "9ddb232f4f517536"
      },
      "id": "9ddb232f4f517536",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Device"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cc40eefd0eaa05f0"
      },
      "id": "cc40eefd0eaa05f0"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# If cuda GPU is available, it will be set as the device otherwise cpu\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:42.234311Z",
          "start_time": "2024-03-30T16:29:42.226943Z"
        },
        "id": "b3ac3e140eca8856"
      },
      "id": "b3ac3e140eca8856",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Transfer model to the device\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:42.247431Z",
          "start_time": "2024-03-30T16:29:42.236322Z"
        },
        "id": "1b543360bc4554b"
      },
      "id": "1b543360bc4554b",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Generate  model summary\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:42.224930Z",
          "start_time": "2024-03-30T16:29:40.837755Z"
        },
        "id": "1a957f13e936a949"
      },
      "id": "1a957f13e936a949",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Loss Function and Optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d1a33fb3f6ff6908"
      },
      "id": "d1a33fb3f6ff6908"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Define loss function and the optimizer\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T16:29:42.260054Z",
          "start_time": "2024-03-30T16:29:42.252981Z"
        },
        "id": "669b1307469f8832"
      },
      "id": "669b1307469f8832",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6f968a2a28030777"
      },
      "id": "6f968a2a28030777"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Train the defined model\n"
      ],
      "metadata": {
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2024-03-30T16:29:42.261063Z"
        },
        "id": "60e69b0014c4237f"
      },
      "id": "60e69b0014c4237f",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Saving and Loading"
      ],
      "metadata": {
        "id": "Mfw0HC99Vkeq"
      },
      "id": "Mfw0HC99Vkeq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving\n",
        "\n"
      ],
      "metadata": {
        "id": "kVl22lJdVdtB"
      },
      "id": "kVl22lJdVdtB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading\n",
        "\n"
      ],
      "metadata": {
        "id": "0UTpI8eCVrVo"
      },
      "id": "0UTpI8eCVrVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once more send the model to the device after loading\n"
      ],
      "metadata": {
        "id": "suxzaTiyVtrQ"
      },
      "id": "suxzaTiyVtrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance with Testset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e79c54f0039db3bf"
      },
      "id": "e79c54f0039db3bf"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Measure performance of the test set\n",
        "\n"
      ],
      "metadata": {
        "is_executing": true,
        "id": "fbe1e1188dbad085"
      },
      "id": "fbe1e1188dbad085",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!** The method we have used here known as freezing, there is another popular method in Transfer Learning that known as fine-tuning. Even though these names use interchangbly, they means to complte different things. Try to redo the task with fine-tuning instead of freezing by yourself :)"
      ],
      "metadata": {
        "id": "FYd2cO7EfgVp"
      },
      "id": "FYd2cO7EfgVp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "In the above cases, we did not utilized any validation set and no hyperparameter tuning has been performed either. So model performance should be able to improve by performing some hyperparameter tuning."
      ],
      "metadata": {
        "collapsed": false,
        "id": "b4dd7a68927c5aed"
      },
      "id": "b4dd7a68927c5aed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Furthermore, try to measure the training and validation set losses/accuracies within the training loop and plot them in a single plot. In this way, we will be able to identify whether model is overfitting or not. In the above case, neither training or validation losses/accuracies were calculated. Try to record the performance once per certain number of batches."
      ],
      "metadata": {
        "collapsed": false,
        "id": "83740c3f826b0765"
      },
      "id": "83740c3f826b0765"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try!**\n",
        "Try to integrate early stopping into the training loop when the model performance w.r.t the validation set is no longer improving with further training. Try to think of a possible logic and add that into the training loop accordingly."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7ac71a674a54e912"
      },
      "id": "7ac71a674a54e912"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance for Different Classes"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3e266ad502f16426"
      },
      "id": "3e266ad502f16426"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Measure the performance w.r.t each class\n"
      ],
      "metadata": {
        "is_executing": true,
        "id": "dfc3e8f7211ab7e1"
      },
      "id": "dfc3e8f7211ab7e1",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}